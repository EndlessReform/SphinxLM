{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reverse search for embeddings\n",
    "\n",
    "Prerequisites:\n",
    "- Base filtered dataset is generated (./create-filtered-dataset-1m.ipynb)\n",
    "- Weaviate and embedding servers are up (./infra/docker-compose.yml)\n",
    "- .env file is created with Weaviate credentials\n",
    "\n",
    "## Embed the queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in ./.venv/lib/python3.11/site-packages (2.14.5)\n",
      "Requirement already satisfied: weaviate-client in ./.venv/lib/python3.11/site-packages (3.24.2)\n",
      "Collecting python-dotenv\n",
      "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in ./.venv/lib/python3.11/site-packages (from datasets) (1.26.1)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in ./.venv/lib/python3.11/site-packages (from datasets) (13.0.0)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in ./.venv/lib/python3.11/site-packages (from datasets) (0.3.7)\n",
      "Requirement already satisfied: pandas in ./.venv/lib/python3.11/site-packages (from datasets) (2.1.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in ./.venv/lib/python3.11/site-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in ./.venv/lib/python3.11/site-packages (from datasets) (4.66.1)\n",
      "Requirement already satisfied: xxhash in ./.venv/lib/python3.11/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in ./.venv/lib/python3.11/site-packages (from datasets) (0.70.15)\n",
      "Requirement already satisfied: fsspec<2023.9.0,>=2023.1.0 in ./.venv/lib/python3.11/site-packages (from fsspec[http]<2023.9.0,>=2023.1.0->datasets) (2023.6.0)\n",
      "Requirement already satisfied: aiohttp in ./.venv/lib/python3.11/site-packages (from datasets) (3.8.6)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in ./.venv/lib/python3.11/site-packages (from datasets) (0.17.3)\n",
      "Requirement already satisfied: packaging in ./.venv/lib/python3.11/site-packages (from datasets) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.11/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: validators<1.0.0,>=0.21.2 in ./.venv/lib/python3.11/site-packages (from weaviate-client) (0.22.0)\n",
      "Requirement already satisfied: authlib<2.0.0,>=1.2.1 in ./.venv/lib/python3.11/site-packages (from weaviate-client) (1.2.1)\n",
      "Requirement already satisfied: cryptography>=3.2 in ./.venv/lib/python3.11/site-packages (from authlib<2.0.0,>=1.2.1->weaviate-client) (41.0.4)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.11/site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in ./.venv/lib/python3.11/site-packages (from aiohttp->datasets) (3.3.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.11/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in ./.venv/lib/python3.11/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./.venv/lib/python3.11/site-packages (from aiohttp->datasets) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.11/site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.venv/lib/python3.11/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.11/site-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.12.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.venv/lib/python3.11/site-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.8.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.11/site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.11/site-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.11/site-packages (from requests>=2.19.0->datasets) (2023.7.22)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.11/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.11/site-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in ./.venv/lib/python3.11/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: cffi>=1.12 in ./.venv/lib/python3.11/site-packages (from cryptography>=3.2->authlib<2.0.0,>=1.2.1->weaviate-client) (1.16.0)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: pycparser in ./.venv/lib/python3.11/site-packages (from cffi>=1.12->cryptography>=3.2->authlib<2.0.0,>=1.2.1->weaviate-client) (2.21)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install datasets weaviate-client python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_parquet('queries_80_20.parquet/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import numpy as np\n",
    "\n",
    "EMB_URL = \"http://localhost:8080/openai\"\n",
    "\n",
    "def create_embedding(url, input_text):\n",
    "    response = requests.post(url, json={'input': input_text})\n",
    "    list_embedding = response.json()[\"data\"][0][\"embedding\"]\n",
    "    # Convert to numpy array\n",
    "    return(np.array(list_embedding))\n",
    "\n",
    "def create_batch_embedding(url, input_texts):\n",
    "    response = requests.post(url, json={'input': input_texts})\n",
    "    list_embedding = list(map(lambda x: x[\"embedding\"], response.json()[\"data\"]))\n",
    "    # Convert to numpy array\n",
    "    return(np.array(list_embedding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def batch_indices(iterable, batch_size):\n",
    "    l = len(iterable)\n",
    "    for ndx in range(0, l, batch_size):\n",
    "        yield iterable[ndx:min(ndx + batch_size, l)]\n",
    "\n",
    "def batch_apply(df_column, batch_size, func, url):\n",
    "    results = []\n",
    "    total_batches = len(df_column) // batch_size \n",
    "    for batch in tqdm(batch_indices(df_column, batch_size), total=total_batches):\n",
    "        batch_result = func(url, batch.tolist())\n",
    "        results.extend(batch_result)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reverse documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test this by embedding [Project Gutenberg's 1000 most popular works](https://www.gutenberg.org/browse/scores/top):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ritsuko/ai/datasets/bing_queries/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"jkeisling/project-gutenberg-top-books-oct-2023\", data_files=\"project-gutenberg-top-1k-fixed-cleaned.csv\")\n",
    "books_df = dataset['train'].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruct \"title by author\" format\n",
    "books_df['document'] = books_df['Title'] + ' by ' + books_df['Author']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16it [00:00, 46.66it/s]                        \n"
     ]
    }
   ],
   "source": [
    "# Embed all documents using batch apply. Yes, I know, this is contrived since the dataset is already embedded upstream, but this is the source.\n",
    "batch_size = 64\n",
    "books_df['embedding'] = batch_apply(books_df['document'], batch_size, create_batch_embedding, EMB_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's persist the embeddings. _Fiat lux!_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv\n",
    "import weaviate\n",
    "import os\n",
    "\n",
    "# Create client\n",
    "client = weaviate.Client(\n",
    "    url = os.environ.get('WEAVIATE_ENDPOINT'),\n",
    "    timeout_config=(2, 15)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not client.schema.exists(\"Document\"):\n",
    "    # Define schema for reverse query documents\n",
    "    class_obj = {\n",
    "        \"class\": \"Document\",\n",
    "        \"vectorizer\": \"none\",\n",
    "    }\n",
    "    client.schema.create_class(class_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'embedding'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/ai/datasets/bing_queries/.venv/lib/python3.11/site-packages/pandas/core/indexes/base.py:3790\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3789\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3790\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3791\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'embedding'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/home/ritsuko/ai/datasets/bing_queries/create-instruction-tuning.ipynb Cell 14\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bmelchior/home/ritsuko/ai/datasets/bing_queries/create-instruction-tuning.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mwith\u001b[39;00m client\u001b[39m.\u001b[39mbatch \u001b[39mas\u001b[39;00m batch:\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bmelchior/home/ritsuko/ai/datasets/bing_queries/create-instruction-tuning.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39mfor\u001b[39;00m i, row \u001b[39min\u001b[39;00m tqdm(books_df\u001b[39m.\u001b[39miterrows(), total\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(books_df)):\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bmelchior/home/ritsuko/ai/datasets/bing_queries/create-instruction-tuning.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m         batch\u001b[39m.\u001b[39madd_data_object(\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bmelchior/home/ritsuko/ai/datasets/bing_queries/create-instruction-tuning.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m             data_object\u001b[39m=\u001b[39m{\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bmelchior/home/ritsuko/ai/datasets/bing_queries/create-instruction-tuning.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mtitle\u001b[39m\u001b[39m\"\u001b[39m: row[\u001b[39m'\u001b[39m\u001b[39mTitle\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bmelchior/home/ritsuko/ai/datasets/bing_queries/create-instruction-tuning.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mauthor\u001b[39m\u001b[39m\"\u001b[39m: row[\u001b[39m'\u001b[39m\u001b[39mAuthor\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bmelchior/home/ritsuko/ai/datasets/bing_queries/create-instruction-tuning.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39mdocument\u001b[39m\u001b[39m\"\u001b[39m: row[\u001b[39m'\u001b[39m\u001b[39mdocument\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bmelchior/home/ritsuko/ai/datasets/bing_queries/create-instruction-tuning.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m             },\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bmelchior/home/ritsuko/ai/datasets/bing_queries/create-instruction-tuning.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m             class_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mDocument\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bmelchior/home/ritsuko/ai/datasets/bing_queries/create-instruction-tuning.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m             vector\u001b[39m=\u001b[39mrow[\u001b[39m'\u001b[39;49m\u001b[39membedding\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39mtolist()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bmelchior/home/ritsuko/ai/datasets/bing_queries/create-instruction-tuning.ipynb#X16sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m         )\n",
      "File \u001b[0;32m~/ai/datasets/bing_queries/.venv/lib/python3.11/site-packages/pandas/core/series.py:1040\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1037\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[key]\n\u001b[1;32m   1039\u001b[0m \u001b[39melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m-> 1040\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_value(key)\n\u001b[1;32m   1042\u001b[0m \u001b[39m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[1;32m   1043\u001b[0m \u001b[39m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[1;32m   1044\u001b[0m \u001b[39mif\u001b[39;00m is_iterator(key):\n",
      "File \u001b[0;32m~/ai/datasets/bing_queries/.venv/lib/python3.11/site-packages/pandas/core/series.py:1156\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1153\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[label]\n\u001b[1;32m   1155\u001b[0m \u001b[39m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[0;32m-> 1156\u001b[0m loc \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex\u001b[39m.\u001b[39;49mget_loc(label)\n\u001b[1;32m   1158\u001b[0m \u001b[39mif\u001b[39;00m is_integer(loc):\n\u001b[1;32m   1159\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values[loc]\n",
      "File \u001b[0;32m~/ai/datasets/bing_queries/.venv/lib/python3.11/site-packages/pandas/core/indexes/base.py:3797\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3792\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(casted_key, \u001b[39mslice\u001b[39m) \u001b[39mor\u001b[39;00m (\n\u001b[1;32m   3793\u001b[0m         \u001b[39misinstance\u001b[39m(casted_key, abc\u001b[39m.\u001b[39mIterable)\n\u001b[1;32m   3794\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39many\u001b[39m(\u001b[39misinstance\u001b[39m(x, \u001b[39mslice\u001b[39m) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m casted_key)\n\u001b[1;32m   3795\u001b[0m     ):\n\u001b[1;32m   3796\u001b[0m         \u001b[39mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3797\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3798\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3799\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3800\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3801\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3802\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'embedding'"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "client.batch.configure(batch_size=1000)\n",
    "with client.batch as batch:\n",
    "    for i, row in tqdm(books_df.iterrows(), total=len(books_df)):\n",
    "        batch.add_data_object(\n",
    "            data_object={\n",
    "                \"title\": row['Title'],\n",
    "                \"author\": row['Author'],\n",
    "                \"document\": row['document'],\n",
    "            },\n",
    "            class_name=\"Document\",\n",
    "            vector=row['embedding'].tolist()\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_documents(client, query, top_k=10, schema=\"Document\"):\n",
    "    embedding = create_embedding(EMB_URL, f\"Represent this sentence for searching relevant passages: ${query}\")\n",
    "    response = (\n",
    "        client.query\n",
    "        .get(schema, [\"title\", \"author\"])\n",
    "        .with_near_vector({\n",
    "            \"vector\": embedding.tolist(),\n",
    "        })\n",
    "        .with_limit(top_k)\n",
    "        .do()\n",
    "    )\n",
    "    print(response)\n",
    "\n",
    "def search_keyphrases(client, query, top_k=10, is_query=True):\n",
    "    prefix = \"Represent this sentence for searching relevant passages: \" if is_query else \"\"\n",
    "    embedding = create_embedding(EMB_URL, prefix + query)\n",
    "    response = (\n",
    "        client.query\n",
    "        .get(\"Keyphrase\", [\"keyphrase\", \"avg_score\"])\n",
    "        .with_near_vector({\n",
    "            \"vector\": embedding.tolist(),\n",
    "        })\n",
    "        .with_limit(top_k)\n",
    "        .do()\n",
    "    )\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': {'Get': {'Document': [{'author': 'William James', 'title': 'The Varieties of Religious Experience: A Study in Human Nature'}, {'author': 'Nietzsche', 'title': 'The Twilight of the Idols; or, How to Philosophize with the Hammer. The Antichrist'}, {'author': 'Émile Durkheim', 'title': 'Les formes élémentaires de la vie religieuse. English'}, {'author': 'Anonymous', 'title': 'Doctrina Christiana'}, {'author': 'G. K. Chesterton', 'title': 'Orthodoxy'}, {'author': 'Anonymous', 'title': 'The King James Version of the Bible'}, {'author': 'Albert Gallatin Mackey', 'title': 'The Symbolism of Freemasonry'}, {'author': 'David Hume', 'title': 'Dialogues Concerning Natural Religion'}, {'author': 'Thomas Inman and M.R.C.S.E. John Newton', 'title': 'Ancient Pagan and Modern Christian Symbolism'}, {'author': 'M. E. Billings', 'title': 'Crimes of Preachers in the United States and Canada'}]}}}\n"
     ]
    }
   ],
   "source": [
    "search_documents(client, \"religion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': {'Get': {'Document': [{'author': 'Friedrich Wilhelm Nietzsche', 'title': 'The Antichrist'}, {'author': 'Ambrose Bierce', 'title': \"The Devil's Dictionary\"}, {'author': 'Nietzsche', 'title': 'The Twilight of the Idols; or, How to Philosophize with the Hammer. The Antichrist'}, {'author': 'Friedrich Wilhelm Nietzsche', 'title': 'Beyond Good and Evil'}, {'author': 'Chester S. Geier', 'title': 'The Venus Evil'}, {'author': 'Moncure Daniel Conway', 'title': 'Demonology and Devil-lore'}, {'author': 'Kurt Vonnegut', 'title': '2 B R 0 2 B'}, {'author': 'Herman Melville', 'title': 'Bartleby, the Scrivener: A Story of Wall-Street'}, {'author': 'Washington Irving', 'title': 'Rip Van Winkle'}, {'author': 'Anonymous', 'title': 'The King James Version of the Bible'}]}}}\n"
     ]
    }
   ],
   "source": [
    "search_documents(client, \"Evil\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Downloads</th>\n",
       "      <th>document</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A Christmas Carol in Prose; Being a Ghost Stor...</td>\n",
       "      <td>Charles Dickens</td>\n",
       "      <td>70650</td>\n",
       "      <td>A Christmas Carol in Prose; Being a Ghost Stor...</td>\n",
       "      <td>[0.0016174316, -0.0793457, 0.036315918, -0.024...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pride and Prejudice</td>\n",
       "      <td>Jane Austen</td>\n",
       "      <td>59636</td>\n",
       "      <td>Pride and Prejudice by Jane Austen</td>\n",
       "      <td>[-0.025238037, -0.020614624, 0.0023059845, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Frankenstein; Or, The Modern Prometheus</td>\n",
       "      <td>Mary Wollstonecraft Shelley</td>\n",
       "      <td>56171</td>\n",
       "      <td>Frankenstein; Or, The Modern Prometheus by Mar...</td>\n",
       "      <td>[-0.01550293, -0.038726807, 0.018920898, -0.02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alice's Adventures in Wonderland</td>\n",
       "      <td>Lewis Carroll</td>\n",
       "      <td>28040</td>\n",
       "      <td>Alice's Adventures in Wonderland by Lewis Carroll</td>\n",
       "      <td>[-0.017807007, -0.033721924, 0.03161621, -0.04...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Adventures of Sherlock Holmes</td>\n",
       "      <td>Arthur Conan Doyle</td>\n",
       "      <td>23345</td>\n",
       "      <td>The Adventures of Sherlock Holmes by Arthur Co...</td>\n",
       "      <td>[0.004436493, -0.021759033, 0.014953613, -0.05...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A Tale of Two Cities</td>\n",
       "      <td>Charles Dickens</td>\n",
       "      <td>23253</td>\n",
       "      <td>A Tale of Two Cities by Charles Dickens</td>\n",
       "      <td>[-0.03189087, -0.058746338, 0.017105103, -0.01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The Scarlet Letter</td>\n",
       "      <td>Nathaniel Hawthorne</td>\n",
       "      <td>22293</td>\n",
       "      <td>The Scarlet Letter by Nathaniel Hawthorne</td>\n",
       "      <td>[0.01763916, -0.018432617, 0.03918457, 0.00870...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A Modest Proposal</td>\n",
       "      <td>Jonathan Swift</td>\n",
       "      <td>22171</td>\n",
       "      <td>A Modest Proposal by Jonathan Swift</td>\n",
       "      <td>[0.012031555, -0.029891968, 0.041748047, -0.01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Moby Dick; Or, The Whale</td>\n",
       "      <td>Herman Melville</td>\n",
       "      <td>22024</td>\n",
       "      <td>Moby Dick; Or, The Whale by Herman Melville</td>\n",
       "      <td>[0.015167236, -0.04067993, 0.022979736, -0.018...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>St. Benedict’s Rule for Monasteries</td>\n",
       "      <td>Anonymous</td>\n",
       "      <td>21228</td>\n",
       "      <td>St. Benedict’s Rule for Monasteries by Anonymous</td>\n",
       "      <td>[-0.048553467, 0.0017318726, 0.035614014, -0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0  A Christmas Carol in Prose; Being a Ghost Stor...   \n",
       "1                                Pride and Prejudice   \n",
       "2            Frankenstein; Or, The Modern Prometheus   \n",
       "3                   Alice's Adventures in Wonderland   \n",
       "4                  The Adventures of Sherlock Holmes   \n",
       "5                               A Tale of Two Cities   \n",
       "6                                 The Scarlet Letter   \n",
       "7                                  A Modest Proposal   \n",
       "8                           Moby Dick; Or, The Whale   \n",
       "9                St. Benedict’s Rule for Monasteries   \n",
       "\n",
       "                        Author  Downloads  \\\n",
       "0              Charles Dickens      70650   \n",
       "1                  Jane Austen      59636   \n",
       "2  Mary Wollstonecraft Shelley      56171   \n",
       "3                Lewis Carroll      28040   \n",
       "4           Arthur Conan Doyle      23345   \n",
       "5              Charles Dickens      23253   \n",
       "6          Nathaniel Hawthorne      22293   \n",
       "7               Jonathan Swift      22171   \n",
       "8              Herman Melville      22024   \n",
       "9                    Anonymous      21228   \n",
       "\n",
       "                                            document  \\\n",
       "0  A Christmas Carol in Prose; Being a Ghost Stor...   \n",
       "1                 Pride and Prejudice by Jane Austen   \n",
       "2  Frankenstein; Or, The Modern Prometheus by Mar...   \n",
       "3  Alice's Adventures in Wonderland by Lewis Carroll   \n",
       "4  The Adventures of Sherlock Holmes by Arthur Co...   \n",
       "5            A Tale of Two Cities by Charles Dickens   \n",
       "6          The Scarlet Letter by Nathaniel Hawthorne   \n",
       "7                A Modest Proposal by Jonathan Swift   \n",
       "8        Moby Dick; Or, The Whale by Herman Melville   \n",
       "9   St. Benedict’s Rule for Monasteries by Anonymous   \n",
       "\n",
       "                                           embedding  \n",
       "0  [0.0016174316, -0.0793457, 0.036315918, -0.024...  \n",
       "1  [-0.025238037, -0.020614624, 0.0023059845, -0....  \n",
       "2  [-0.01550293, -0.038726807, 0.018920898, -0.02...  \n",
       "3  [-0.017807007, -0.033721924, 0.03161621, -0.04...  \n",
       "4  [0.004436493, -0.021759033, 0.014953613, -0.05...  \n",
       "5  [-0.03189087, -0.058746338, 0.017105103, -0.01...  \n",
       "6  [0.01763916, -0.018432617, 0.03918457, 0.00870...  \n",
       "7  [0.012031555, -0.029891968, 0.041748047, -0.01...  \n",
       "8  [0.015167236, -0.04067993, 0.022979736, -0.018...  \n",
       "9  [-0.048553467, 0.0017318726, 0.035614014, -0.0...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # persist to parquet\n",
    "books_df.to_parquet('books.parquet')\n",
    "books_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full embed upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<weaviate.batch.crud_batch.Batch at 0x7fb8dfd8b7d0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Iterate over all queries and create embeddings, persist to weaviate\n",
    "from tqdm import tqdm\n",
    "\n",
    "client.batch.configure(batch_size=128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try reverse search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if client.schema.exists(\"Keyphrase\"):\n",
    "    client.schema.delete_class(\"Keyphrase\")\n",
    "\n",
    "# Define schema for reverse query documents\n",
    "class_obj = {\n",
    "        \"class\": \"Keyphrase\",\n",
    "        \"vectorizer\": \"none\",\n",
    "    }\n",
    "client.schema.create_class(class_obj)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ritsuko/ai/datasets/bing_queries/.venv/lib/python3.11/site-packages/numpy/core/fromnumeric.py:59: FutureWarning: 'DataFrame.swapaxes' is deprecated and will be removed in a future version. Please use 'DataFrame.transpose' instead.\n",
      "  return bound(*args, **kwds)\n",
      "100%|██████████| 15629/15629 [29:59<00:00,  8.69it/s]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "# Iterate over subset as test\n",
    "with client.batch as batch:\n",
    "    n_chunks = math.ceil(len(df) / 64)\n",
    "    chunks = np.array_split(df, n_chunks)\n",
    "\n",
    "    for chunk in tqdm(chunks, total=n_chunks):\n",
    "        # Embed keyphrase\n",
    "        embeddings = create_batch_embedding(EMB_URL, (\"Represent this sentence for searching relevant passages: \" + chunk['clean_keyphrase']).tolist())\n",
    "        # Add embedding to chunk\n",
    "        chunk['embedding'] = embeddings.tolist()\n",
    "\n",
    "        for i, row in chunk.iterrows():\n",
    "            batch.add_data_object(\n",
    "                data_object={\n",
    "                    \"keyphrase\": row['clean_keyphrase'],\n",
    "                    \"avg_score\": row['avg_score'],\n",
    "                },\n",
    "                class_name=\"Keyphrase\",\n",
    "                vector=row['embedding']\n",
    "            )\n",
    "        \n",
    "        # Must do this explicitly to avoid memory leak and OOM\n",
    "        del chunk['embedding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data': {'Get': {'Keyphrase': [{'avg_score': 470,\n",
       "     'keyphrase': 'digital transformation solutions'},\n",
       "    {'avg_score': 2479.1666666666665, 'keyphrase': 'digital transformation'},\n",
       "    {'avg_score': 481.6666666666667, 'keyphrase': 'business transformation'},\n",
       "    {'avg_score': 1.25, 'keyphrase': 'esys company'},\n",
       "    {'avg_score': 622.5, 'keyphrase': 'cloud data integration solutions'},\n",
       "    {'avg_score': 867.5, 'keyphrase': 'small business software systems'},\n",
       "    {'avg_score': 36.666666666666664, 'keyphrase': 'digital office systems'},\n",
       "    {'avg_score': 689.5833333333334, 'keyphrase': 'enterprise software'},\n",
       "    {'avg_score': 0.4166666666666667,\n",
       "     'keyphrase': 'systems development company'},\n",
       "    {'avg_score': 1776.6666666666667, 'keyphrase': 'esolutions'},\n",
       "    {'avg_score': 32147.083333333332,\n",
       "     'keyphrase': 'business cloud integration service'},\n",
       "    {'avg_score': 1264.5833333333333,\n",
       "     'keyphrase': 'enterprise data integration'},\n",
       "    {'avg_score': 0.4166666666666667, 'keyphrase': 'smart system solutions'},\n",
       "    {'avg_score': 651.25, 'keyphrase': 'business cloud integration'},\n",
       "    {'avg_score': 517.5, 'keyphrase': 'intech'},\n",
       "    {'avg_score': 1969.5833333333333, 'keyphrase': 'information systems'},\n",
       "    {'avg_score': 3848.3333333333335, 'keyphrase': 'sysinternals'},\n",
       "    {'avg_score': 8438.75, 'keyphrase': 'enterprise cloud services'},\n",
       "    {'avg_score': 570.4166666666666, 'keyphrase': 'business it services'},\n",
       "    {'avg_score': 1.25, 'keyphrase': 'microsoft systems integrator'},\n",
       "    {'avg_score': 836.6666666666666, 'keyphrase': 'sysinternals suite'},\n",
       "    {'avg_score': 488.3333333333333,\n",
       "     'keyphrase': 'enterprise intranet platform'},\n",
       "    {'avg_score': 4.166666666666667, 'keyphrase': 'isystems evolution'},\n",
       "    {'avg_score': 2093.75, 'keyphrase': 'integris'},\n",
       "    {'avg_score': 1850.4166666666667,\n",
       "     'keyphrase': 'big data solutions companies'},\n",
       "    {'avg_score': 651.6666666666666, 'keyphrase': 'infosync ultipro com'},\n",
       "    {'avg_score': 494.1666666666667, 'keyphrase': 'edi integration'},\n",
       "    {'avg_score': 577.9166666666666, 'keyphrase': 'intranet solutions'},\n",
       "    {'avg_score': 549.1666666666666, 'keyphrase': 'intec'},\n",
       "    {'avg_score': 580.8333333333334, 'keyphrase': 'intuit merchant services'},\n",
       "    {'avg_score': 408.75, 'keyphrase': 'data center services'},\n",
       "    {'avg_score': 1300.4166666666667,\n",
       "     'keyphrase': 'computer integrated systems design'},\n",
       "    {'avg_score': 0.4166666666666667,\n",
       "     'keyphrase': 'international merchant processing solutions'},\n",
       "    {'avg_score': 9455.416666666666, 'keyphrase': 'eservices'},\n",
       "    {'avg_score': 1533.75, 'keyphrase': 'employer eservices'},\n",
       "    {'avg_score': 1690.4166666666667,\n",
       "     'keyphrase': 'business software solutions'},\n",
       "    {'avg_score': 1925.8333333333333, 'keyphrase': 'unisys'},\n",
       "    {'avg_score': 476.25, 'keyphrase': 'it companies'},\n",
       "    {'avg_score': 533.3333333333334,\n",
       "     'keyphrase': 'small business erp systems'},\n",
       "    {'avg_score': 6078.333333333333, 'keyphrase': 'saas'},\n",
       "    {'avg_score': 771.6666666666666, 'keyphrase': 'icsolutions com'},\n",
       "    {'avg_score': 3047.0833333333335, 'keyphrase': 'it services'},\n",
       "    {'avg_score': 568.75, 'keyphrase': 'computer systems'},\n",
       "    {'avg_score': 2657.9166666666665, 'keyphrase': 'cloud based solutions'},\n",
       "    {'avg_score': 1227.5, 'keyphrase': 'software as service'},\n",
       "    {'avg_score': 827.9166666666666,\n",
       "     'keyphrase': 'cloud services small businesses'},\n",
       "    {'avg_score': 408.75, 'keyphrase': 'transystems'},\n",
       "    {'avg_score': 688.75, 'keyphrase': 'big data analytics solutions'},\n",
       "    {'avg_score': 782.5, 'keyphrase': 'iscsi'},\n",
       "    {'avg_score': 643.3333333333334,\n",
       "     'keyphrase': 'software defined networking'}]}}}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_keyphrases(client, 'For over 25 years, Intesys has helped medium and large businesses digitally transform their processes through design, development, and implementation with open architecture enterprise applications. Intesys, a Digital Transformation Partner, based in Italy, offers specialized solutions for their unique clients in all different industries.', 50, is_query=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Addendum: Book clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's cluster them all, for funsies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting umap-learn\n",
      "  Downloading umap-learn-0.5.4.tar.gz (90 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.8/90.8 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in ./.venv/lib/python3.11/site-packages (from umap-learn) (1.26.1)\n",
      "Requirement already satisfied: scipy>=1.3.1 in ./.venv/lib/python3.11/site-packages (from umap-learn) (1.11.3)\n",
      "Requirement already satisfied: scikit-learn>=0.22 in ./.venv/lib/python3.11/site-packages (from umap-learn) (1.3.1)\n",
      "Collecting numba>=0.51.2 (from umap-learn)\n",
      "  Downloading numba-0.58.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.7 kB)\n",
      "Collecting pynndescent>=0.5 (from umap-learn)\n",
      "  Downloading pynndescent-0.5.10.tar.gz (1.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: tqdm in ./.venv/lib/python3.11/site-packages (from umap-learn) (4.66.1)\n",
      "Collecting tbb>=2019.0 (from umap-learn)\n",
      "  Downloading tbb-2021.10.0-py2.py3-none-manylinux1_x86_64.whl.metadata (1.0 kB)\n",
      "Collecting llvmlite<0.42,>=0.41.0dev0 (from numba>=0.51.2->umap-learn)\n",
      "  Downloading llvmlite-0.41.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: joblib>=0.11 in ./.venv/lib/python3.11/site-packages (from pynndescent>=0.5->umap-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./.venv/lib/python3.11/site-packages (from scikit-learn>=0.22->umap-learn) (3.2.0)\n",
      "Downloading numba-0.58.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m54.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tbb-2021.10.0-py2.py3-none-manylinux1_x86_64.whl (4.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m55.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading llvmlite-0.41.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 MB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: umap-learn, pynndescent\n",
      "  Building wheel for umap-learn (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for umap-learn: filename=umap_learn-0.5.4-py3-none-any.whl size=86770 sha256=0649cc9c59780adf79fe24e850627103b8169aea4b785e024234eb723be3991d\n",
      "  Stored in directory: /home/ritsuko/.cache/pip/wheels/42/7b/35/c53136bf6554719351c45217002d767ed2582664997ed2db43\n",
      "  Building wheel for pynndescent (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pynndescent: filename=pynndescent-0.5.10-py3-none-any.whl size=55615 sha256=f07db9f5bb29bf3faa37a7a3769e12455d78734ae214a97f36668c43ada08f1c\n",
      "  Stored in directory: /home/ritsuko/.cache/pip/wheels/a9/a3/51/2411ea852380d31c4cbfee910744f4effe1fef7438b199d496\n",
      "Successfully built umap-learn pynndescent\n",
      "Installing collected packages: tbb, llvmlite, numba, pynndescent, umap-learn\n",
      "Successfully installed llvmlite-0.41.1 numba-0.58.1 pynndescent-0.5.10 tbb-2021.10.0 umap-learn-0.5.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install umap-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'books_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/ritsuko/ai/datasets/bing_queries/create-instruction-tuning.ipynb Cell 15\u001b[0m line \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bmelchior/home/ritsuko/ai/datasets/bing_queries/create-instruction-tuning.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m silhouette_score\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bmelchior/home/ritsuko/ai/datasets/bing_queries/create-instruction-tuning.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# Create a dataframe with just the embeddings\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bmelchior/home/ritsuko/ai/datasets/bing_queries/create-instruction-tuning.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m X \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(books_df[\u001b[39m'\u001b[39m\u001b[39membedding\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mtolist())\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bmelchior/home/ritsuko/ai/datasets/bing_queries/create-instruction-tuning.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# Reduce dimensionality with UMAP\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bmelchior/home/ritsuko/ai/datasets/bing_queries/create-instruction-tuning.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mumap\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'books_df' is not defined"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "\n",
    "# Let's cluster the books\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Create a dataframe with just the embeddings\n",
    "X = pd.DataFrame(books_df['embedding'].tolist())\n",
    "\n",
    "# Reduce dimensionality with UMAP\n",
    "import umap\n",
    "reducer = umap.UMAP(n_components=32)\n",
    "X = reducer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ritsuko/ai/datasets/bing_queries/.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_clusters = 2 The average silhouette_score is : 0.37293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ritsuko/ai/datasets/bing_queries/.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_clusters = 4 The average silhouette_score is : 0.32302183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ritsuko/ai/datasets/bing_queries/.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_clusters = 8 The average silhouette_score is : 0.32309246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ritsuko/ai/datasets/bing_queries/.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_clusters = 16 The average silhouette_score is : 0.35084388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ritsuko/ai/datasets/bing_queries/.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_clusters = 32 The average silhouette_score is : 0.40294448\n"
     ]
    }
   ],
   "source": [
    "# Create a range of cluster sizes to try\n",
    "cluster_range = [2**x for x in range(1, 6)]\n",
    "\n",
    "# For each cluster size, fit a KMeans model and print the silhouette score\n",
    "for n_clusters in cluster_range:\n",
    "    clusterer = KMeans(n_clusters=n_clusters, random_state=10)\n",
    "    cluster_labels = clusterer.fit_predict(X)\n",
    "    silhouette_avg = silhouette_score(X, cluster_labels)\n",
    "    print(\"For n_clusters =\", n_clusters,\n",
    "          \"The average silhouette_score is :\", silhouette_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ritsuko/ai/datasets/bing_queries/.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    }
   ],
   "source": [
    "# apply kmeans with 32 clusters\n",
    "clusterer = KMeans(n_clusters=16, random_state=10)\n",
    "cluster_labels = clusterer.fit_predict(X)\n",
    "\n",
    "# Add cluster labels to dataframe\n",
    "books_df['cluster'] = cluster_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cluster\n",
       "4     108\n",
       "12    107\n",
       "7      82\n",
       "2      81\n",
       "13     76\n",
       "0      70\n",
       "1      62\n",
       "14     62\n",
       "6      62\n",
       "10     54\n",
       "3      51\n",
       "9      51\n",
       "5      47\n",
       "8      38\n",
       "11     37\n",
       "15     12\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books_df[\"cluster\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'books_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/ritsuko/ai/datasets/bing_queries/create-instruction-tuning.ipynb Cell 32\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bmelchior/home/ritsuko/ai/datasets/bing_queries/create-instruction-tuning.ipynb#X43sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m books_df[books_df[\u001b[39m\"\u001b[39m\u001b[39mcluster\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m3\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mdocument\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mhead(\u001b[39m10\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'books_df' is not defined"
     ]
    }
   ],
   "source": [
    "books_df[books_df[\"cluster\"] == 3][\"document\"].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop embeddings and save to csv\n",
    "books_df.drop(columns=['embedding']).to_csv('books_with_clusters.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
