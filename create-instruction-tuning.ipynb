{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reverse search for embeddings\n",
    "## Embed the queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in ./.venv/lib/python3.11/site-packages (2.14.5)\n",
      "Requirement already satisfied: numpy>=1.17 in ./.venv/lib/python3.11/site-packages (from datasets) (1.26.1)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in ./.venv/lib/python3.11/site-packages (from datasets) (13.0.0)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in ./.venv/lib/python3.11/site-packages (from datasets) (0.3.7)\n",
      "Requirement already satisfied: pandas in ./.venv/lib/python3.11/site-packages (from datasets) (2.1.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in ./.venv/lib/python3.11/site-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in ./.venv/lib/python3.11/site-packages (from datasets) (4.66.1)\n",
      "Requirement already satisfied: xxhash in ./.venv/lib/python3.11/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in ./.venv/lib/python3.11/site-packages (from datasets) (0.70.15)\n",
      "Requirement already satisfied: fsspec<2023.9.0,>=2023.1.0 in ./.venv/lib/python3.11/site-packages (from fsspec[http]<2023.9.0,>=2023.1.0->datasets) (2023.6.0)\n",
      "Requirement already satisfied: aiohttp in ./.venv/lib/python3.11/site-packages (from datasets) (3.8.6)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in ./.venv/lib/python3.11/site-packages (from datasets) (0.17.3)\n",
      "Requirement already satisfied: packaging in ./.venv/lib/python3.11/site-packages (from datasets) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.11/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.11/site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in ./.venv/lib/python3.11/site-packages (from aiohttp->datasets) (3.3.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.11/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in ./.venv/lib/python3.11/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./.venv/lib/python3.11/site-packages (from aiohttp->datasets) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.11/site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.venv/lib/python3.11/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.11/site-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.12.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.venv/lib/python3.11/site-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.8.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.11/site-packages (from requests>=2.19.0->datasets) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.11/site-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.11/site-packages (from requests>=2.19.0->datasets) (2023.7.22)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.11/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.11/site-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in ./.venv/lib/python3.11/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_parquet('queries_80_20.parquet/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ping server to make sure it's up\n",
    "import requests\n",
    "import numpy as np\n",
    "\n",
    "EMB_URL = \"http://localhost:8080/openai\"\n",
    "\n",
    "def create_embedding(url, input_text):\n",
    "    response = requests.post(url, json={'input': input_text})\n",
    "    list_embedding = response.json()[\"data\"][0][\"embedding\"]\n",
    "    # Convert to numpy array\n",
    "    return(np.array(list_embedding))\n",
    "\n",
    "def create_batch_embedding(url, input_texts):\n",
    "    response = requests.post(url, json={'input': input_texts})\n",
    "    list_embedding = list(map(lambda x: x[\"embedding\"], response.json()[\"data\"]))\n",
    "    # Convert to numpy array\n",
    "    return(np.array(list_embedding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def batch_indices(iterable, batch_size):\n",
    "    l = len(iterable)\n",
    "    for ndx in range(0, l, batch_size):\n",
    "        yield iterable[ndx:min(ndx + batch_size, l)]\n",
    "\n",
    "def batch_apply(df_column, batch_size, func, url):\n",
    "    results = []\n",
    "    total_batches = len(df_column) // batch_size \n",
    "    for batch in tqdm(batch_indices(df_column, batch_size), total=total_batches):\n",
    "        batch_result = func(url, batch.tolist())\n",
    "        results.extend(batch_result)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_keyphrase</th>\n",
       "      <th>avg_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100 free death record search</td>\n",
       "      <td>0.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1610a</td>\n",
       "      <td>2.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18 cargo trailer</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1973 jeep cj5 specifications</td>\n",
       "      <td>0.416667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1a sehen de</td>\n",
       "      <td>0.416667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                clean_keyphrase  avg_score\n",
       "0  100 free death record search   0.416667\n",
       "1                         1610a   2.083333\n",
       "2              18 cargo trailer   0.833333\n",
       "3  1973 jeep cj5 specifications   0.416667\n",
       "4                   1a sehen de   0.416667"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's experiment on a subset of the queries. This takes a jiffy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1562 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1563it [00:25, 61.97it/s]                          \n"
     ]
    }
   ],
   "source": [
    "# Time for 100k subset to sanity check\n",
    "df_subset = df.sample(int(1e5), random_state=42)\n",
    "# Batch apply 32 at a time\n",
    "batch_size = 64\n",
    "df_subset['embedding'] = batch_apply(df_subset['clean_keyphrase'], batch_size, create_batch_embedding, EMB_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reverse documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test this by embedding [Project Gutenberg's 1000 most popular works](https://www.gutenberg.org/browse/scores/top):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ritsuko/ai/datasets/bing_queries/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"jkeisling/project-gutenberg-top-books-oct-2023\", data_files=\"project-gutenberg-top-1k-fixed-cleaned.csv\")\n",
    "books_df = dataset['train'].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruct \"title by author\" format\n",
    "books_df['document'] = books_df['Title'] + ' by ' + books_df['Author']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16it [00:00, 43.02it/s]                        \n"
     ]
    }
   ],
   "source": [
    "# Embed all documents using batch apply. Yes, I know, this is contrived since the dataset is already embedded upstream, but this is the source.\n",
    "batch_size = 64\n",
    "books_df['embedding'] = batch_apply(books_df['document'], batch_size, create_batch_embedding, EMB_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Downloads</th>\n",
       "      <th>document</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A Christmas Carol in Prose; Being a Ghost Stor...</td>\n",
       "      <td>Charles Dickens</td>\n",
       "      <td>70650</td>\n",
       "      <td>A Christmas Carol in Prose; Being a Ghost Stor...</td>\n",
       "      <td>[0.0016174316, -0.0793457, 0.036315918, -0.024...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pride and Prejudice</td>\n",
       "      <td>Jane Austen</td>\n",
       "      <td>59636</td>\n",
       "      <td>Pride and Prejudice by Jane Austen</td>\n",
       "      <td>[-0.025238037, -0.020614624, 0.0023059845, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Frankenstein; Or, The Modern Prometheus</td>\n",
       "      <td>Mary Wollstonecraft Shelley</td>\n",
       "      <td>56171</td>\n",
       "      <td>Frankenstein; Or, The Modern Prometheus by Mar...</td>\n",
       "      <td>[-0.01550293, -0.038726807, 0.018920898, -0.02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alice's Adventures in Wonderland</td>\n",
       "      <td>Lewis Carroll</td>\n",
       "      <td>28040</td>\n",
       "      <td>Alice's Adventures in Wonderland by Lewis Carroll</td>\n",
       "      <td>[-0.017807007, -0.033721924, 0.03161621, -0.04...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Adventures of Sherlock Holmes</td>\n",
       "      <td>Arthur Conan Doyle</td>\n",
       "      <td>23345</td>\n",
       "      <td>The Adventures of Sherlock Holmes by Arthur Co...</td>\n",
       "      <td>[0.004436493, -0.021759033, 0.014953613, -0.05...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A Tale of Two Cities</td>\n",
       "      <td>Charles Dickens</td>\n",
       "      <td>23253</td>\n",
       "      <td>A Tale of Two Cities by Charles Dickens</td>\n",
       "      <td>[-0.03189087, -0.058746338, 0.017105103, -0.01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The Scarlet Letter</td>\n",
       "      <td>Nathaniel Hawthorne</td>\n",
       "      <td>22293</td>\n",
       "      <td>The Scarlet Letter by Nathaniel Hawthorne</td>\n",
       "      <td>[0.01763916, -0.018432617, 0.03918457, 0.00870...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A Modest Proposal</td>\n",
       "      <td>Jonathan Swift</td>\n",
       "      <td>22171</td>\n",
       "      <td>A Modest Proposal by Jonathan Swift</td>\n",
       "      <td>[0.012031555, -0.029891968, 0.041748047, -0.01...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Moby Dick; Or, The Whale</td>\n",
       "      <td>Herman Melville</td>\n",
       "      <td>22024</td>\n",
       "      <td>Moby Dick; Or, The Whale by Herman Melville</td>\n",
       "      <td>[0.015167236, -0.04067993, 0.022979736, -0.018...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>St. Benedict’s Rule for Monasteries</td>\n",
       "      <td>Anonymous</td>\n",
       "      <td>21228</td>\n",
       "      <td>St. Benedict’s Rule for Monasteries by Anonymous</td>\n",
       "      <td>[-0.048553467, 0.0017318726, 0.035614014, -0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0  A Christmas Carol in Prose; Being a Ghost Stor...   \n",
       "1                                Pride and Prejudice   \n",
       "2            Frankenstein; Or, The Modern Prometheus   \n",
       "3                   Alice's Adventures in Wonderland   \n",
       "4                  The Adventures of Sherlock Holmes   \n",
       "5                               A Tale of Two Cities   \n",
       "6                                 The Scarlet Letter   \n",
       "7                                  A Modest Proposal   \n",
       "8                           Moby Dick; Or, The Whale   \n",
       "9                St. Benedict’s Rule for Monasteries   \n",
       "\n",
       "                        Author  Downloads  \\\n",
       "0              Charles Dickens      70650   \n",
       "1                  Jane Austen      59636   \n",
       "2  Mary Wollstonecraft Shelley      56171   \n",
       "3                Lewis Carroll      28040   \n",
       "4           Arthur Conan Doyle      23345   \n",
       "5              Charles Dickens      23253   \n",
       "6          Nathaniel Hawthorne      22293   \n",
       "7               Jonathan Swift      22171   \n",
       "8              Herman Melville      22024   \n",
       "9                    Anonymous      21228   \n",
       "\n",
       "                                            document  \\\n",
       "0  A Christmas Carol in Prose; Being a Ghost Stor...   \n",
       "1                 Pride and Prejudice by Jane Austen   \n",
       "2  Frankenstein; Or, The Modern Prometheus by Mar...   \n",
       "3  Alice's Adventures in Wonderland by Lewis Carroll   \n",
       "4  The Adventures of Sherlock Holmes by Arthur Co...   \n",
       "5            A Tale of Two Cities by Charles Dickens   \n",
       "6          The Scarlet Letter by Nathaniel Hawthorne   \n",
       "7                A Modest Proposal by Jonathan Swift   \n",
       "8        Moby Dick; Or, The Whale by Herman Melville   \n",
       "9   St. Benedict’s Rule for Monasteries by Anonymous   \n",
       "\n",
       "                                           embedding  \n",
       "0  [0.0016174316, -0.0793457, 0.036315918, -0.024...  \n",
       "1  [-0.025238037, -0.020614624, 0.0023059845, -0....  \n",
       "2  [-0.01550293, -0.038726807, 0.018920898, -0.02...  \n",
       "3  [-0.017807007, -0.033721924, 0.03161621, -0.04...  \n",
       "4  [0.004436493, -0.021759033, 0.014953613, -0.05...  \n",
       "5  [-0.03189087, -0.058746338, 0.017105103, -0.01...  \n",
       "6  [0.01763916, -0.018432617, 0.03918457, 0.00870...  \n",
       "7  [0.012031555, -0.029891968, 0.041748047, -0.01...  \n",
       "8  [0.015167236, -0.04067993, 0.022979736, -0.018...  \n",
       "9  [-0.048553467, 0.0017318726, 0.035614014, -0.0...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " # persist to parquet\n",
    "books_df.to_parquet('books.parquet')\n",
    "books_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try reverse search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "def search(query_embedding, all_embeddings, top_k=16):\n",
    "    distances = cdist([query_embedding], all_embeddings, metric='cosine')\n",
    "    indices = np.argsort(distances)[0][:top_k]\n",
    "    return indices\n",
    "\n",
    "def retrieve_documents(indices, df):\n",
    "    # Return all matching documents\n",
    "    return df.iloc[indices]['clean_keyphrase'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_query_embeddings = np.vstack(df_subset['embedding'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['christmas carol book',\n",
       " 'christmas poem',\n",
       " 'christmas carol george c scott',\n",
       " 'charles dickens biography',\n",
       " 'politics prose',\n",
       " 'scrooge',\n",
       " 'caroling',\n",
       " 'great expectations',\n",
       " 'moral story',\n",
       " 'lyrics christmas songs',\n",
       " 'theme moral story',\n",
       " 'poem written iambic pentameter',\n",
       " 'wordsworth',\n",
       " 'stephen king',\n",
       " 'last christmas',\n",
       " 'tom sawyer book',\n",
       " 'creative writing',\n",
       " 'tone literature',\n",
       " 'nat king cole christmas song',\n",
       " 'christmas chronicles',\n",
       " 'james joyce',\n",
       " 'free literature book',\n",
       " 'christmas puns',\n",
       " 'tall tale',\n",
       " 'short narrative',\n",
       " 'f scott fitzgerald',\n",
       " 'finding father christmas',\n",
       " 'yuletide',\n",
       " 'nathaniel hawthorne',\n",
       " 'william blake',\n",
       " 'mark twain',\n",
       " 'lament son book']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieve_documents(search(books_df.iloc[0][\"embedding\"], all_query_embeddings, top_k=32), df_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Addendum: Book clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's cluster them all, for funsies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting umap-learn\n",
      "  Downloading umap-learn-0.5.4.tar.gz (90 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.8/90.8 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in ./.venv/lib/python3.11/site-packages (from umap-learn) (1.26.1)\n",
      "Requirement already satisfied: scipy>=1.3.1 in ./.venv/lib/python3.11/site-packages (from umap-learn) (1.11.3)\n",
      "Requirement already satisfied: scikit-learn>=0.22 in ./.venv/lib/python3.11/site-packages (from umap-learn) (1.3.1)\n",
      "Collecting numba>=0.51.2 (from umap-learn)\n",
      "  Downloading numba-0.58.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.7 kB)\n",
      "Collecting pynndescent>=0.5 (from umap-learn)\n",
      "  Downloading pynndescent-0.5.10.tar.gz (1.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: tqdm in ./.venv/lib/python3.11/site-packages (from umap-learn) (4.66.1)\n",
      "Collecting tbb>=2019.0 (from umap-learn)\n",
      "  Downloading tbb-2021.10.0-py2.py3-none-manylinux1_x86_64.whl.metadata (1.0 kB)\n",
      "Collecting llvmlite<0.42,>=0.41.0dev0 (from numba>=0.51.2->umap-learn)\n",
      "  Downloading llvmlite-0.41.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: joblib>=0.11 in ./.venv/lib/python3.11/site-packages (from pynndescent>=0.5->umap-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./.venv/lib/python3.11/site-packages (from scikit-learn>=0.22->umap-learn) (3.2.0)\n",
      "Downloading numba-0.58.1-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m54.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tbb-2021.10.0-py2.py3-none-manylinux1_x86_64.whl (4.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m55.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading llvmlite-0.41.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 MB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: umap-learn, pynndescent\n",
      "  Building wheel for umap-learn (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for umap-learn: filename=umap_learn-0.5.4-py3-none-any.whl size=86770 sha256=0649cc9c59780adf79fe24e850627103b8169aea4b785e024234eb723be3991d\n",
      "  Stored in directory: /home/ritsuko/.cache/pip/wheels/42/7b/35/c53136bf6554719351c45217002d767ed2582664997ed2db43\n",
      "  Building wheel for pynndescent (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pynndescent: filename=pynndescent-0.5.10-py3-none-any.whl size=55615 sha256=f07db9f5bb29bf3faa37a7a3769e12455d78734ae214a97f36668c43ada08f1c\n",
      "  Stored in directory: /home/ritsuko/.cache/pip/wheels/a9/a3/51/2411ea852380d31c4cbfee910744f4effe1fef7438b199d496\n",
      "Successfully built umap-learn pynndescent\n",
      "Installing collected packages: tbb, llvmlite, numba, pynndescent, umap-learn\n",
      "Successfully installed llvmlite-0.41.1 numba-0.58.1 pynndescent-0.5.10 tbb-2021.10.0 umap-learn-0.5.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install umap-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'books_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/ritsuko/ai/datasets/bing_queries/create-instruction-tuning.ipynb Cell 15\u001b[0m line \u001b[0;36m8\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bmelchior/home/ritsuko/ai/datasets/bing_queries/create-instruction-tuning.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m silhouette_score\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bmelchior/home/ritsuko/ai/datasets/bing_queries/create-instruction-tuning.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# Create a dataframe with just the embeddings\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bmelchior/home/ritsuko/ai/datasets/bing_queries/create-instruction-tuning.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m X \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mDataFrame(books_df[\u001b[39m'\u001b[39m\u001b[39membedding\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mtolist())\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bmelchior/home/ritsuko/ai/datasets/bing_queries/create-instruction-tuning.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# Reduce dimensionality with UMAP\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bmelchior/home/ritsuko/ai/datasets/bing_queries/create-instruction-tuning.ipynb#X21sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mumap\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'books_df' is not defined"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "\n",
    "# Let's cluster the books\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Create a dataframe with just the embeddings\n",
    "X = pd.DataFrame(books_df['embedding'].tolist())\n",
    "\n",
    "# Reduce dimensionality with UMAP\n",
    "import umap\n",
    "reducer = umap.UMAP(n_components=32)\n",
    "X = reducer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ritsuko/ai/datasets/bing_queries/.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_clusters = 2 The average silhouette_score is : 0.37293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ritsuko/ai/datasets/bing_queries/.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_clusters = 4 The average silhouette_score is : 0.32302183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ritsuko/ai/datasets/bing_queries/.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_clusters = 8 The average silhouette_score is : 0.32309246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ritsuko/ai/datasets/bing_queries/.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_clusters = 16 The average silhouette_score is : 0.35084388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ritsuko/ai/datasets/bing_queries/.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_clusters = 32 The average silhouette_score is : 0.40294448\n"
     ]
    }
   ],
   "source": [
    "# Create a range of cluster sizes to try\n",
    "cluster_range = [2**x for x in range(1, 6)]\n",
    "\n",
    "# For each cluster size, fit a KMeans model and print the silhouette score\n",
    "for n_clusters in cluster_range:\n",
    "    clusterer = KMeans(n_clusters=n_clusters, random_state=10)\n",
    "    cluster_labels = clusterer.fit_predict(X)\n",
    "    silhouette_avg = silhouette_score(X, cluster_labels)\n",
    "    print(\"For n_clusters =\", n_clusters,\n",
    "          \"The average silhouette_score is :\", silhouette_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ritsuko/ai/datasets/bing_queries/.venv/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    }
   ],
   "source": [
    "# apply kmeans with 32 clusters\n",
    "clusterer = KMeans(n_clusters=16, random_state=10)\n",
    "cluster_labels = clusterer.fit_predict(X)\n",
    "\n",
    "# Add cluster labels to dataframe\n",
    "books_df['cluster'] = cluster_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cluster\n",
       "4     108\n",
       "12    107\n",
       "7      82\n",
       "2      81\n",
       "13     76\n",
       "0      70\n",
       "1      62\n",
       "14     62\n",
       "6      62\n",
       "10     54\n",
       "3      51\n",
       "9      51\n",
       "5      47\n",
       "8      38\n",
       "11     37\n",
       "15     12\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books_df[\"cluster\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37           The Wonderful Wizard of Oz by L. Frank Baum\n",
       "40                          The Prophet by Kahlil Gibran\n",
       "61     Baron Trump's Marvellous Underground Journey b...\n",
       "79                  The Turn of the Screw by Henry James\n",
       "81                    The Jungle Book by Rudyard Kipling\n",
       "86                          The Jungle by Upton Sinclair\n",
       "173             The King in Yellow by Robert W. Chambers\n",
       "177           The Wind in the Willows by Kenneth Grahame\n",
       "197                   Just So Stories by Rudyard Kipling\n",
       "221    The Pilgrim's Progress from this world to that...\n",
       "Name: document, dtype: object"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "books_df[books_df[\"cluster\"] == 3][\"document\"].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop embeddings and save to csv\n",
    "books_df.drop(columns=['embedding']).to_csv('books_with_clusters.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
